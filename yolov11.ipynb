{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"YOLO11 Tutorial","provenance":[],"toc_visible":true},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9785603,"sourceType":"datasetVersion","datasetId":5995578},{"sourceId":139093,"sourceType":"modelInstanceVersion","modelInstanceId":117776,"modelId":141013}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div align=\"center\">\n  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n\n<a href=\"https://docs.ultralytics.com/zh\">‰∏≠Êñá</a> | <a href=\"https://docs.ultralytics.com/ko\">ÌïúÍµ≠Ïñ¥</a> | <a href=\"https://docs.ultralytics.com/ja\">Êó•Êú¨Ë™û</a> | <a href=\"https://docs.ultralytics.com/ru\">–†—É—Å—Å–∫–∏–π</a> | <a href=\"https://docs.ultralytics.com/de\">Deutsch</a> | <a href=\"https://docs.ultralytics.com/fr\">Fran√ßais</a> | <a href=\"https://docs.ultralytics.com/es\">Espa√±ol</a> | <a href=\"https://docs.ultralytics.com/pt\">Portugu√™s</a> | <a href=\"https://docs.ultralytics.com/tr\">T√ºrk√ße</a> | <a href=\"https://docs.ultralytics.com/vi\">Ti·∫øng Vi·ªát</a> | <a href=\"https://docs.ultralytics.com/ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a><br>\n\n  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yaml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yaml/badge.svg\" alt=\"Ultralytics CI\"></a><a href=\"https://console.paperspace.com/github/ultralytics/ultralytics\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"/></a><a href=\"https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a><a href=\"https://www.kaggle.com/ultralytics/yolov8\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n\n<a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a><a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a><a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n\nWelcome to the Ultralytics YOLO11 üöÄ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. This notebook serves as the starting point for exploring the various resources available to help you get started with YOLO11 and understand its features and capabilities.\n\nYOLO11 models are fast, accurate, and easy to use, making them ideal for various object detection and image segmentation tasks. They can be trained on large datasets and run on diverse hardware platforms, from CPUs to GPUs.\n\nWe hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!\n\n</div>","metadata":{"id":"t6MPjfT5NrKQ"}},{"cell_type":"markdown","source":"# Setup\n\nPip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n\n[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://pepy.tech/project/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)","metadata":{"id":"7mGmQbAO5pQb"}},{"cell_type":"code","source":"%pip install ultralytics\nimport ultralytics\nultralytics.checks()","metadata":{"id":"wbvMlHd_QwMG","outputId":"2e992f9f-90bb-4668-de12-fed629975285","trusted":true,"execution":{"iopub.status.busy":"2024-11-02T07:23:52.954772Z","iopub.execute_input":"2024-11-02T07:23:52.955140Z","iopub.status.idle":"2024-11-02T07:25:20.176941Z","shell.execute_reply.started":"2024-11-02T07:23:52.955106Z","shell.execute_reply":"2024-11-02T07:25:20.175485Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.27 üöÄ Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\nSetup complete ‚úÖ (4 CPUs, 31.4 GB RAM, 5933.9/8062.4 GB disk)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# 1. Predict\n\n\n\nYOLO11 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLO11 Predict Docs](https://docs.ultralytics.com/modes/train/).\n","metadata":{"id":"4JnkELT0cIJg"}},{"cell_type":"code","source":"pip install -U ultralytics wandb","metadata":{"id":"zR9ZbuQCH7FX","outputId":"e3ebec6f-658a-4803-d80c-e07d12908767","trusted":true,"execution":{"iopub.status.busy":"2024-11-02T07:27:29.111897Z","iopub.execute_input":"2024-11-02T07:27:29.112796Z","iopub.status.idle":"2024-11-02T07:27:41.158940Z","shell.execute_reply.started":"2024-11-02T07:27:29.112751Z","shell.execute_reply":"2024-11-02T07:27:41.157815Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ultralytics in /opt/conda/lib/python3.10/site-packages (8.3.27)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.5)\nRequirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.1)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: ultralytics-thop>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.10)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.15.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.10/site-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\n<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/212889447-69e5bdf1-5800-4e29-835e-2ed2336dede2.jpg\" width=\"600\">","metadata":{"id":"hkAzDWJ7cWTr"}},{"cell_type":"markdown","source":"# 2. Val\n\nValidate a model's accuracy on the [COCO](https://docs.ultralytics.com/datasets/detect/coco/) dataset's `val` or `test` splits. The latest YOLO11 [models](https://github.com/ultralytics/ultralytics#models) are downloaded automatically the first time they are used. See [YOLO11 Val Docs](https://docs.ultralytics.com/modes/val/) for more information.","metadata":{"id":"0eq1SMWl6Sfn"}},{"cell_type":"code","source":"import wandb\n\n# Initialize your Weights & Biases environment\nwandb.login(key=\" \")","metadata":{"id":"WQPtK1QYVaD_","trusted":true,"execution":{"iopub.status.busy":"2024-11-02T07:36:04.274265Z","iopub.execute_input":"2024-11-02T07:36:04.274646Z","iopub.status.idle":"2024-11-02T07:36:06.309660Z","shell.execute_reply.started":"2024-11-02T07:36:04.274610Z","shell.execute_reply":"2024-11-02T07:36:06.308793Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"id":"X58w8JLpMnjH","outputId":"af2a5deb-029b-466d-96a4-bd3e406987fa"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Train\n\n\n\n<p align=\"\"><a href=\"https://ultralytics.com/hub\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/yolov8/banner-integrations.png\"/></a></p>\n\n\n\nTrain YOLO11 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLO11 Train Docs](https://docs.ultralytics.com/modes/train/) for more information.","metadata":{"id":"ZY2VXXXu74w5"}},{"cell_type":"code","source":"# Install Dataset\n!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"4wd1c4Ny1GIOeSzG0gvc\")\nproject = rf.workspace(\"shyn-vcwnu\").project(\"ken-ys3ip\")\nversion = project.version(3)\ndataset = version.download(\"yolov11\")\n                ","metadata":{"id":"ktegpM42AooT","trusted":true,"execution":{"iopub.status.busy":"2024-11-02T07:28:58.170214Z","iopub.execute_input":"2024-11-02T07:28:58.170645Z","iopub.status.idle":"2024-11-02T07:29:15.530927Z","shell.execute_reply.started":"2024-11-02T07:28:58.170605Z","shell.execute_reply":"2024-11-02T07:29:15.529993Z"}},"outputs":[{"name":"stdout","text":"Collecting roboflow\n  Downloading roboflow-1.1.48-py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from roboflow) (2024.8.30)\nRequirement already satisfied: idna==3.7 in /opt/conda/lib/python3.10/site-packages (from roboflow) (3.7)\nRequirement already satisfied: cycler in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.4.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from roboflow) (3.7.5)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.4)\nRequirement already satisfied: opencv-python-headless==4.10.0.84 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.10.0.84)\nRequirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from roboflow) (10.3.0)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.9.0.post0)\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.32.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.16.0)\nRequirement already satisfied: urllib3>=1.26.6 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.18)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.66.4)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (6.0.2)\nRequirement already satisfied: requests-toolbelt in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.10.1)\nCollecting filetype (from roboflow)\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (1.2.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (4.53.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->roboflow) (3.3.2)\nDownloading roboflow-1.1.48-py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nInstalling collected packages: filetype, roboflow\nSuccessfully installed filetype-1.2.0 roboflow-1.1.48\nloading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"},{"name":"stderr","text":"Downloading Dataset Version Zip in ken-3 to yolov11:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 130405/130405 [00:02<00:00, 47657.34it/s]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"\nExtracting Dataset Version Zip to ken-3 in yolov11:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8064/8064 [00:00<00:00, 8275.43it/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Train YOLO11n on COCO8 for 3 epochs\n!yolo train model=yolo11s.pt data=/kaggle/input/ketamm/data.yaml epochs=120 imgsz=640 lr0=0.0005 patience=50","metadata":{"id":"1NcFxRcFdJ_O","outputId":"952f35f7-666f-4121-fbdf-2b3a33b28081","trusted":true,"execution":{"iopub.status.busy":"2024-11-02T07:38:02.770284Z","iopub.execute_input":"2024-11-02T07:38:02.771295Z","iopub.status.idle":"2024-11-02T09:04:37.258366Z","shell.execute_reply.started":"2024-11-02T07:38:02.771251Z","shell.execute_reply":"2024-11-02T09:04:37.256798Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt to 'yolo11s.pt'...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.4M/18.4M [00:00<00:00, 102MB/s]\nUltralytics 8.3.27 üöÄ Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11s.pt, data=/kaggle/input/ketamm/data.yaml, epochs=120, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.0005, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 12.9MB/s]\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n 23        [16, 19, 22]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nYOLO11s summary: 319 layers, 9,428,179 parameters, 9,428,163 gradients, 21.5 GFLOPs\n\nTransferred 493/499 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 60.8MB/s]\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/ken-3/train/labels... 3775 images, 0 backgrounds\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/ken-3/train/labels.cache\n/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ken-3/valid/labels... 201 images, 0 backgrounds, 0\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/ken-3/valid/labels.cache\nPlotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0005' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 120 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      1/120      4.41G     0.7767     0.7134      1.017        125        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.973       0.99      0.993      0.856\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      2/120      4.36G     0.7641     0.4419      1.009        108        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.974      0.957      0.981      0.746\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      3/120       4.4G     0.7594     0.4334      1.007         97        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.977      0.981      0.992      0.871\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      4/120      4.36G     0.7389     0.4187     0.9992        104        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.984      0.993      0.994      0.884\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      5/120      4.33G     0.7299     0.3999     0.9976         96        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.993      0.995      0.995       0.87\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      6/120      4.37G     0.7196     0.3885     0.9904         82        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.987      0.956      0.981      0.873\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      7/120      4.33G     0.7085     0.3806     0.9867        112        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.981      0.989      0.994      0.865\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      8/120      4.36G     0.6951     0.3694     0.9819         88        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.992      0.997      0.995      0.881\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      9/120      4.39G     0.6754     0.3602      0.974        126        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.999       0.99      0.995       0.87\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     10/120      4.31G     0.6753     0.3569     0.9743        104        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.989      0.996      0.995      0.924\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     11/120      4.36G     0.6675     0.3489     0.9706        104        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.995      0.994      0.995      0.932\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     12/120      4.33G     0.6663     0.3479     0.9733        105        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.986      0.995      0.994      0.925\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     13/120      4.36G     0.6655     0.3427     0.9712        101        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.991      0.996      0.995      0.948\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     14/120      4.37G     0.6478     0.3327     0.9658         97        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.993      0.997      0.995      0.891\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     15/120      4.36G     0.6447     0.3279     0.9588        161        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.993      0.989      0.995      0.914\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     16/120      4.33G     0.6409     0.3298     0.9591         93        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.996      0.992      0.995       0.92\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     17/120      4.37G     0.6451     0.3296     0.9586         92        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.989      0.998      0.995      0.941\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     18/120      4.37G     0.6316     0.3257      0.958        125        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.994      0.994      0.995      0.949\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     19/120      4.38G     0.6254     0.3159     0.9507        111        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.994      0.993      0.995      0.946\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     20/120      4.36G      0.625     0.3169     0.9516         98        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.995      0.997      0.995       0.94\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     21/120      4.33G     0.6196     0.3177      0.958         70        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.999      0.991      0.995      0.945\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     22/120      4.37G     0.6192      0.314      0.955        122        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.988      0.999      0.995      0.952\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     23/120      4.37G     0.6117     0.3126     0.9465         88        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.995      0.995      0.995      0.956\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     24/120      4.36G     0.6083      0.308     0.9492        123        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.997      0.995      0.995      0.945\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     25/120      4.36G     0.6086     0.3098     0.9509         89        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.991      0.997      0.995      0.956\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     26/120      4.36G     0.6093     0.3042     0.9488         97        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.993      0.998      0.995      0.959\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     27/120      4.33G     0.5968     0.3013     0.9425        110        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.997      0.993      0.995      0.951\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     28/120      4.33G     0.5972     0.3011     0.9455        111        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.991      0.994      0.995      0.959\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     29/120      4.36G     0.5952     0.2984     0.9448         98        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.993      0.993      0.995      0.952\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     30/120      4.36G     0.5893     0.2965     0.9435        102        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.989      0.998      0.995      0.963\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     31/120      4.33G     0.5956        0.3     0.9465        118        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.994      0.996      0.995      0.962\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     32/120      4.36G     0.5919     0.2988     0.9442         70        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.993      0.996      0.995      0.964\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     33/120      4.36G     0.5785     0.2899     0.9365        153        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.996      0.994      0.995      0.958\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     34/120      4.34G      0.581     0.2934     0.9347         85        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.999      0.992      0.995      0.958\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     35/120      4.33G     0.5764     0.2911     0.9402        118        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.997      0.993      0.995      0.961\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     36/120      4.37G     0.5651     0.2878     0.9334        120        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.997      0.994      0.995      0.957\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     37/120      4.36G     0.5635     0.2844     0.9344        117        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.993      0.997      0.995      0.958\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     38/120      4.36G     0.5661      0.286     0.9355        140        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.991      0.996      0.995      0.969\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     39/120      4.33G     0.5534     0.2811     0.9314        113        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.993      0.997      0.995      0.969\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     40/120      4.33G     0.5506     0.2803     0.9311         80        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.995      0.997      0.995      0.966\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     41/120      4.36G     0.5401     0.2769     0.9263         82        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.998      0.995      0.995      0.964\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     42/120      4.33G     0.5419     0.2758     0.9267         93        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.996      0.993      0.995      0.967\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     43/120      4.34G     0.5414     0.2741     0.9268         81        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.996      0.995      0.995      0.969\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     44/120      4.34G      0.533     0.2696     0.9246        118        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.999      0.995      0.995      0.971\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     45/120      4.36G     0.5338     0.2725     0.9253         83        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.995      0.993      0.995      0.972\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     46/120      4.33G     0.5382     0.2691     0.9266         80        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.995      0.998      0.995      0.968\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     47/120      4.37G     0.5289     0.2694      0.923        118        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.988      0.998      0.995      0.967\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     48/120      4.33G     0.5278     0.2693     0.9225        132        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881       0.99      0.999      0.995      0.969\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     49/120      4.34G     0.5256     0.2674     0.9214         99        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.993      0.997      0.995      0.974\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     50/120      4.36G     0.5222     0.2656     0.9191        114        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.995      0.997      0.995      0.974\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     51/120      4.33G      0.523     0.2658     0.9201        104        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.998      0.994      0.995      0.972\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     52/120      4.36G     0.5243     0.2666     0.9238        125        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.998      0.994      0.995      0.973\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     53/120      4.33G     0.5159     0.2612     0.9178        127        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.996      0.998      0.995      0.972\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     54/120      4.36G     0.5163     0.2608     0.9194        121        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.994      0.998      0.995      0.975\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     55/120      4.38G     0.5096     0.2605     0.9183         90        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.997      0.995      0.995      0.972\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     56/120      4.33G     0.5104     0.2605     0.9196        102        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.997      0.995      0.995      0.974\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     57/120      4.33G     0.5037     0.2553     0.9128         98        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.993      0.997      0.995      0.969\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     58/120      4.39G     0.5009     0.2549     0.9169         97        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.997      0.994      0.995      0.972\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     59/120      4.34G     0.5034     0.2568     0.9138         80        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881          1      0.993      0.995      0.976\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     60/120      4.39G        0.5     0.2564     0.9145         86        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.998      0.994      0.995      0.973\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     61/120      4.34G     0.4999     0.2538     0.9133         91        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.996      0.997      0.995      0.972\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     62/120      4.36G     0.4983     0.2547     0.9144         86        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.997      0.996      0.995      0.975\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     63/120      4.33G     0.4978     0.2532     0.9131        129        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.998      0.995      0.995      0.974\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     64/120      4.37G     0.4993     0.2554     0.9165         88        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.997      0.997      0.995      0.975\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     65/120      4.36G     0.4943     0.2498     0.9112         93        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.998      0.995      0.995      0.976\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     66/120      4.33G     0.4859     0.2475     0.9104        115        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.997      0.994      0.995      0.976\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     67/120      4.36G     0.4912     0.2506     0.9088        114        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.995      0.996      0.995      0.976\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     68/120      4.33G     0.4821     0.2448     0.9069        120        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.994      0.997      0.995      0.976\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     69/120      4.33G     0.4861     0.2475     0.9097        123        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.999      0.993      0.995      0.975\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     70/120      4.34G     0.4766     0.2423     0.9043         93        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.998      0.993      0.995      0.978\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     71/120      4.36G     0.4814     0.2472     0.9056         57        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.995      0.997      0.995      0.977\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     72/120      4.33G     0.4791     0.2438     0.9046        120        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.998      0.997      0.995      0.975\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     73/120      4.33G     0.4821     0.2443     0.9063        100        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.995      0.998      0.995      0.976\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     74/120      4.33G     0.4751     0.2407     0.9021         58        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.997      0.997      0.995      0.975\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     75/120      4.34G     0.4816     0.2447     0.9052         90        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.994      0.999      0.995      0.974\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     76/120      4.33G     0.4797     0.2422     0.9041        108        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.997      0.999      0.995      0.977\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     77/120      4.36G     0.4731     0.2384     0.9018        105        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        201        881      0.995      0.997      0.995      0.976\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     78/120      4.33G       0.47     0.2372     0.9029        132        640:  ^C\n     78/120      4.33G       0.47     0.2372     0.9029        132        640:  \nTraceback (most recent call last):\n  File \"/opt/conda/bin/yolo\", line 8, in <module>\n    sys.exit(entrypoint())\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/cfg/__init__.py\", line 826, in entrypoint\n    getattr(model, mode)(**overrides)  # default args from model\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 802, in train\n    self.trainer.train()\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 207, in train\n    self._do_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 413, in _do_train\n    pbar.set_description(\n  File \"/opt/conda/lib/python3.10/site-packages/tqdm/std.py\", line 1382, in set_description\n    def set_description(self, desc=None, refresh=True):\nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# 4. Export\n\nExport a YOLO11 model to any supported format below with the `format` argument, i.e. `format=onnx`. See [YOLO11 Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n\n- üí° ProTip: Export to [ONNX](https://docs.ultralytics.com/integrations/onnx/) or [OpenVINO](https://docs.ultralytics.com/integrations/openvino/) for up to 3x CPU speedup.  \n- üí° ProTip: Export to [TensorRT](https://docs.ultralytics.com/integrations/tensorrt/) for up to 5x GPU speedup.\n\n| Format                                                                   | `format` Argument | Model                     | Metadata | Arguments                                                            |\n|--------------------------------------------------------------------------|-------------------|---------------------------|----------|----------------------------------------------------------------------|\n| [PyTorch](https://pytorch.org/)                                          | -                 | `yolo11n.pt`              | ‚úÖ        | -                                                                    |\n| [TorchScript](https://docs.ultralytics.com/integrations/torchscript)     | `torchscript`     | `yolo11n.torchscript`     | ‚úÖ        | `imgsz`, `optimize`, `batch`                                         |\n| [ONNX](https://docs.ultralytics.com/integrations/onnx)                   | `onnx`            | `yolo11n.onnx`            | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `opset`, `batch`             |\n| [OpenVINO](https://docs.ultralytics.com/integrations/openvino)           | `openvino`        | `yolo11n_openvino_model/` | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n| [TensorRT](https://docs.ultralytics.com/integrations/tensorrt)           | `engine`          | `yolo11n.engine`          | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `workspace`, `int8`, `batch` |\n| [CoreML](https://docs.ultralytics.com/integrations/coreml)               | `coreml`          | `yolo11n.mlpackage`       | ‚úÖ        | `imgsz`, `half`, `int8`, `nms`, `batch`                              |\n| [TF SavedModel](https://docs.ultralytics.com/integrations/tf-savedmodel) | `saved_model`     | `yolo11n_saved_model/`    | ‚úÖ        | `imgsz`, `keras`, `int8`, `batch`                                    |\n| [TF GraphDef](https://docs.ultralytics.com/integrations/tf-graphdef)     | `pb`              | `yolo11n.pb`              | ‚ùå        | `imgsz`, `batch`                                                     |\n| [TF Lite](https://docs.ultralytics.com/integrations/tflite)              | `tflite`          | `yolo11n.tflite`          | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n| [TF Edge TPU](https://docs.ultralytics.com/integrations/edge-tpu)        | `edgetpu`         | `yolo11n_edgetpu.tflite`  | ‚úÖ        | `imgsz`                                                              |\n| [TF.js](https://docs.ultralytics.com/integrations/tfjs)                  | `tfjs`            | `yolo11n_web_model/`      | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n| [PaddlePaddle](https://docs.ultralytics.com/integrations/paddlepaddle)   | `paddle`          | `yolo11n_paddle_model/`   | ‚úÖ        | `imgsz`, `batch`                                                     |\n| [NCNN](https://docs.ultralytics.com/integrations/ncnn)                   | `ncnn`            | `yolo11n_ncnn_model/`     | ‚úÖ        | `imgsz`, `half`, `batch`                                             |","metadata":{"id":"nPZZeNrLCQG6"}},{"cell_type":"code","source":"!yolo export model=yolo11n.pt format=torchscript","metadata":{"id":"CYIjW4igCjqD","outputId":"5357fa04-6749-4508-effe-8d4078533539"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Python Usage\n\n\n\nYOLO11 was reimagined using Python-first principles for the most seamless Python YOLO experience yet. YOLO11 models can be loaded from a trained checkpoint or created from scratch. Then methods are used to train, val, predict, and export the model. See detailed Python usage examples in the [YOLO11 Python Docs](https://docs.ultralytics.com/usage/python/).","metadata":{"id":"kUMOQ0OeDBJG"}},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load a model\nmodel = YOLO('yolo11n.yaml')  # build a new model from scratch\nmodel = YOLO('yolo11n.pt')  # load a pretrained model (recommended for training)\n\n# Use the model\nresults = model.train(data='coco8.yaml', epochs=3)  # train the model\nresults = model.val()  # evaluate model performance on the validation set\nresults = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\nresults = model.export(format='onnx')  # export the model to ONNX format","metadata":{"id":"bpF9-vS_DAaf"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Tasks\n\n\n\nYOLO11 can train, val, predict and export models for the most common tasks in vision AI: [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/). See [YOLO11 Tasks Docs](https://docs.ultralytics.com/tasks/) for more information.\n\n\n\n<br><img width=\"1024\" src=\"https://raw.githubusercontent.com/ultralytics/assets/main/im/banner-tasks.png\">\n","metadata":{"id":"Phm9ccmOKye5"}},{"cell_type":"markdown","source":"## 1. Detection\n\n\n\nYOLO11 _detection_ models have no suffix and are the default YOLO11 models, i.e. `yolo11n.pt` and are pretrained on COCO. See [Detection Docs](https://docs.ultralytics.com/tasks/detect/) for full details.\n","metadata":{"id":"yq26lwpYK1lq"}},{"cell_type":"code","source":"# Load YOLO11n, train it on COCO128 for 3 epochs and predict an image with it\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolo11n.pt')  # load a pretrained YOLO detection model\nmodel.train(data='coco8.yaml', epochs=3)  # train the model\nmodel('https://ultralytics.com/images/bus.jpg')  # predict on an image","metadata":{"id":"8Go5qqS9LbC5"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Segmentation\n\n\n\nYOLO11 _segmentation_ models use the `-seg` suffix, i.e. `yolo11n-seg.pt` and are pretrained on COCO. See [Segmentation Docs](https://docs.ultralytics.com/tasks/segment/) for full details.\n","metadata":{"id":"7ZW58jUzK66B"}},{"cell_type":"code","source":"# Load YOLO11n-seg, train it on COCO128-seg for 3 epochs and predict an image with it\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolo11n-seg.pt')  # load a pretrained YOLO segmentation model\nmodel.train(data='coco8-seg.yaml', epochs=3)  # train the model\nmodel('https://ultralytics.com/images/bus.jpg')  # predict on an image","metadata":{"id":"WFPJIQl_L5HT"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Classification\n\n\n\nYOLO11 _classification_ models use the `-cls` suffix, i.e. `yolo11n-cls.pt` and are pretrained on ImageNet. See [Classification Docs](https://docs.ultralytics.com/tasks/classify/) for full details.\n","metadata":{"id":"ax3p94VNK9zR"}},{"cell_type":"code","source":"# Load YOLO11n-cls, train it on mnist160 for 3 epochs and predict an image with it\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolo11n-cls.pt')  # load a pretrained YOLO classification model\nmodel.train(data='mnist160', epochs=3)  # train the model\nmodel('https://ultralytics.com/images/bus.jpg')  # predict on an image","metadata":{"id":"5q9Zu6zlL5rS"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Pose\n\n\n\nYOLO11 _pose_ models use the `-pose` suffix, i.e. `yolo11n-pose.pt` and are pretrained on COCO Keypoints. See [Pose Docs](https://docs.ultralytics.com/tasks/pose/) for full details.","metadata":{"id":"SpIaFLiO11TG"}},{"cell_type":"code","source":"# Load YOLO11n-pose, train it on COCO8-pose for 3 epochs and predict an image with it\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolo11n-pose.pt')  # load a pretrained YOLO pose model\nmodel.train(data='coco8-pose.yaml', epochs=3)  # train the model\nmodel('https://ultralytics.com/images/bus.jpg')  # predict on an image","metadata":{"id":"si4aKFNg19vX"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Oriented Bounding Boxes (OBB)\n\n\n\nYOLO11 _OBB_ models use the `-obb` suffix, i.e. `yolo11n-obb.pt` and are pretrained on the DOTA dataset. See [OBB Docs](https://docs.ultralytics.com/tasks/obb/) for full details.","metadata":{"id":"cf5j_T9-B5F0"}},{"cell_type":"code","source":"# Load YOLO11n-obb, train it on DOTA8 for 3 epochs and predict an image with it\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolo11n-obb.pt')  # load a pretrained YOLO OBB model\nmodel.train(data='dota8.yaml', epochs=3)  # train the model\nmodel('https://ultralytics.com/images/bus.jpg')  # predict on an image","metadata":{"id":"IJNKClOOB5YS"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Appendix\n\n\n\nAdditional content below.","metadata":{"id":"IEijrePND_2I"}},{"cell_type":"code","source":"# Pip install from source\n!pip install git+https://github.com/ultralytics/ultralytics@main","metadata":{"id":"pIdE6i8C3LYp"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Git clone and run tests on updates branch\n!git clone https://github.com/ultralytics/ultralytics -b main\n%pip install -qe ultralytics","metadata":{"id":"uRKlwxSJdhd1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run tests (Git clone only)\n!pytest ultralytics/tests","metadata":{"id":"GtPlh7mcCGZX"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Validate multiple models\nfor x in 'nsmlx':\n  !yolo val model=yolo11{x}.pt data=coco.yaml","metadata":{"id":"Wdc6t_bfzDDk"},"outputs":[],"execution_count":null}]}